{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78bc27f-2ffb-4bcb-80ca-21b54f254bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psycopg2 in /home/alex/.local/lib/python3.12/site-packages (2.9.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2 --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c887c0e-2117-4917-b58f-dc7761f676a2",
   "metadata": {},
   "source": [
    "# Consumer for sales data stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1e6e4-a70a-45f3-97d2-9b5d54d28b6a",
   "metadata": {},
   "source": [
    "The notebook's purpose is to create a subscriber of the `sales_topic` Kafka topic, which generates sales data of the retail company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576a9a11-d741-4e99-bec6-4406146574a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from confluent_kafka import Consumer, KafkaException, KafkaError\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fcd2be1-d037-4efd-97e1-1ffc8cd06672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c102ac-57fd-4d30-9fa5-c0477b689e53",
   "metadata": {},
   "source": [
    "### Defining the conexion for cloud datawarehouse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70cdc01-0933-4fa4-a648-8f35bcb47f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSPORT'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf41f6c4-7ed9-4727-8f40-d4eb9fdbc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_row(sales_record):\n",
    "    \"\"\"\n",
    "    Insert sales row to datawarehouse with postgres conexion\n",
    "\n",
    "    Params:\n",
    "    sales_record (dict): Row record of sales, processed before\n",
    "    \"\"\"\n",
    "    try: \n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        query = \"\"\"\n",
    "            INSERT INTO sales (sku, site_code, quantity, date) \n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(query, (\n",
    "            sales_record['sku'], \n",
    "            sales_record['site_code'], \n",
    "            sales_record['quantity'], \n",
    "            sales_record['date'].strftime('%Y-%m-%d')  # Format the date\n",
    "        ))\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        verify_query = \"\"\"\n",
    "            SELECT * FROM sales \n",
    "            WHERE site_code = %s AND sku = %s AND date = %s\n",
    "        \"\"\"\n",
    "        cursor.execute(verify_query, (\n",
    "            sales_record['site_code'],\n",
    "            sales_record['sku'],\n",
    "            sales_record['date'].strftime('%Y-%m-%d')  # Format the date for comparison\n",
    "        ))\n",
    "\n",
    "        inserted_record = cursor.fetchone()\n",
    "\n",
    "        if inserted_record:\n",
    "            print(f\"Inserted record successfully: {inserted_record}\")\n",
    "        else:\n",
    "            print(\"Record not found after insertion.\")        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        conn.rollback()\n",
    "    finally: \n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca1800-eb07-43d7-915e-e91b885d12e7",
   "metadata": {},
   "source": [
    "### Kafka consumer for sales topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee64bed-30f0-482c-bcdf-64ed2ca6a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = Consumer({\n",
    "    'bootstrap.servers': os.getenv('KAFKA_SERVER'), \n",
    "    'group.id': 'sales_consumer_group',\n",
    "    'auto.offset.reset': 'earliest',\n",
    "})\n",
    "\n",
    "topic = 'sales_topic'\n",
    "consumer.subscribe([topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41424e61-67cc-40e9-9b34-4fc5b6a08fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date):\n",
    "    date = pd.to_datetime(date)\n",
    "    if date is None or pd.isna(date): \n",
    "        return pd.to_datetime('today')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ff8357-4eb4-4df9-8a2a-39f46486d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data):\n",
    "    \"\"\"Process soh rows and handling special cases\"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        return dict()\n",
    "    if 'date' not in data.keys(): \n",
    "        data['date'] = 'today'\n",
    "\n",
    "    if 'quantity' not in data.keys() or data['quantity'] is None:\n",
    "        data['quantity'] = 1\n",
    "    \n",
    "    data['date'] = parse_date(data['date'])\n",
    "    \n",
    "    for col in ['site_code', 'store']:\n",
    "        if col in data.keys() and data[col] is not None:\n",
    "            data['site_code'] = data[col].upper()\n",
    "    \n",
    "    data['quantity'] = max(data['quantity'], 0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89edead4-8afb-45fc-ab21-a7b30b08d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message(msg):\n",
    "    \"\"\"\n",
    "    Function to process the message of the Kafka topic and store it into a database\n",
    "\n",
    "    Params: \n",
    "    msg (cimp.Message): Message to process\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sales_record = loads(msg.value().decode('utf-8'))\n",
    "    \n",
    "        sales_record = pipeline(sales_record)\n",
    "    \n",
    "        cols = ['sku', 'date', 'quantity', 'site_code']\n",
    "    \n",
    "        if set(cols).issubset(sales_record.keys()) and all(sales_record[key] is not None for key in cols):\n",
    "            insert_row(sales_record)\n",
    "        \n",
    "        print(f'Message processed: {sales_record}')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab87baf-5576-49e1-9599-08362a081500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_messages():\n",
    "    try:\n",
    "        while True:\n",
    "            msg = consumer.poll(timeout=1.0)\n",
    "\n",
    "            if msg is None:\n",
    "                continue  # No new message, keep polling\n",
    "\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    print(f\"End of partition reached {msg.partition}, offset {msg.offset}\")\n",
    "                else:\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                process_message(msg)\n",
    "                consumer.commit(message=msg, asynchronous=False)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Consuming interrupted.\")\n",
    "    finally:\n",
    "        consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d187e8ee-4247-4e30-aa4c-ec62b179e055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consuming interrupted.\n"
     ]
    }
   ],
   "source": [
    "consume_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
