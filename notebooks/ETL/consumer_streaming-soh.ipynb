{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4ffa13-30cd-4882-8fa7-489c794d2a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psycopg2 in /home/alex/.local/lib/python3.12/site-packages (2.9.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2 --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08235874-edef-4b69-9c60-e9f7c7253e44",
   "metadata": {},
   "source": [
    "# Consumer for soh streamline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfa807-d06b-4a8a-a00b-ec6ebf58d617",
   "metadata": {},
   "source": [
    "The notebook's purpose is to create a subscriber for `soh-topic` where data related to soh is processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a48a074-99bb-4aa1-9f2a-0495456608c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException, KafkaError\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../../libraries')\n",
    "import utils\n",
    "\n",
    "from json import loads\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bbfebf-c5df-4c98-b767-207df08f4d5e",
   "metadata": {},
   "source": [
    "### Defining the connection to datawarehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84893c0-11ec-40f4-875e-9d54ce4d8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4db3a7e-d429-4c24-9abd-96e2590e248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_row(soh_record):\n",
    "    \"\"\"\n",
    "    Insert soh row to datawarehouse with postgres connection\n",
    "\n",
    "    Params:\n",
    "    soh_record (dict): Row record of soh, processed before\n",
    "    \"\"\"\n",
    "    try: \n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO soh (site_code, sku, quantity, date) \n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(insert_query, (\n",
    "            soh_record['site_code'], \n",
    "            soh_record['sku'], \n",
    "            soh_record['quantity'], \n",
    "            soh_record['date']\n",
    "        ))\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        verify_query = \"\"\"\n",
    "            SELECT * FROM soh \n",
    "            WHERE site_code = %s AND sku = %s AND date = %s\n",
    "        \"\"\"\n",
    "        cursor.execute(verify_query, (\n",
    "            soh_record['site_code'],\n",
    "            soh_record['sku'],\n",
    "            soh_record['date']\n",
    "        ))\n",
    "\n",
    "        inserted_record = cursor.fetchone()\n",
    "\n",
    "        if inserted_record:\n",
    "            print(f\"Inserted record successfully: {inserted_record}\")\n",
    "        else:\n",
    "            print(\"Record not found after insertion.\")        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        conn.rollback()\n",
    "    finally: \n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a814a-1e8f-4172-aff3-5d82c636f19a",
   "metadata": {},
   "source": [
    "### Kafka Consumer for `soh-topic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b32f6ac-4d21-4c7c-ac28-5c893580633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = Consumer({\n",
    "    'bootstrap.servers': os.getenv('KAFKA_SERVER'),\n",
    "    'group.id': 'soh_consumer_group',\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'enable.auto.commit': False,            \n",
    "})\n",
    "\n",
    "topic = 'soh_topic'\n",
    "consumer.subscribe([topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8adb008-03da-4a2f-a8e4-bd9915def286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date):\n",
    "    \"\"\"Function to parse the date format to SQL storage\"\"\"\n",
    "    date = pd.to_datetime(date)\n",
    "    if date is None or pd.isna(date): \n",
    "        return pd.to_datetime('today')\n",
    "    return date.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a03008-5453-4ac2-8bd4-4285af627aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data):\n",
    "    \"\"\"Process soh rows and handling special cases\"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        return dict()\n",
    "    if 'date' not in data.keys(): \n",
    "        data['date'] = 'today'\n",
    "\n",
    "    if 'quantity' not in data.keys() or data['quantity'] is None:\n",
    "        data['quantity'] = 0\n",
    "    \n",
    "    data['date'] = parse_date(data['date'])\n",
    "    \n",
    "    for col in ['site_code', 'store']:\n",
    "        if col in data.keys() and data[col] is not None:\n",
    "            data['site_code'] = data[col].upper()\n",
    "    \n",
    "    data['quantity'] = max(data['quantity'], 0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafdf3a5-5679-496f-b998-0166d6f00eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message(msg):\n",
    "    \"\"\"\n",
    "    Function to process Kafka messages\n",
    "\n",
    "    Params:\n",
    "    msg (cimp.Message): Message to process\n",
    "    \"\"\"\n",
    "    try:\n",
    "        soh_record = loads(msg.value().decode('utf-8'))\n",
    "\n",
    "        soh_record = pipeline(soh_record)\n",
    "    \n",
    "        cols = ['sku', 'date', 'quantity', 'site_code']\n",
    "    \n",
    "        if set(cols).issubset(soh_record.keys()) and all(soh_record[key] is not None for key in cols):\n",
    "            insert_row(soh_record)\n",
    "        print(f\"Processed message: {soh_record}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01656046-c925-4ac6-94dc-41743f27da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_messages():\n",
    "    try:\n",
    "        while True:\n",
    "            msg = consumer.poll(timeout=1.0)\n",
    "\n",
    "            if msg is None:\n",
    "                continue  # no message\n",
    "\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    print(f\"End of partition reached {msg.partition}, offset {msg.offset}\")\n",
    "                else:\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                process_message(msg)\n",
    "\n",
    "                consumer.commit(message=msg, asynchronous=False)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Consuming interrupted.\")\n",
    "    finally:\n",
    "        consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "321a4b2c-a94f-4dfb-9a0e-b89dd09588a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consuming interrupted.\n"
     ]
    }
   ],
   "source": [
    "consume_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
