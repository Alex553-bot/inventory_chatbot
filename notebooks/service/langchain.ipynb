{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5afb58e-1c2a-45c2-b0ea-5ebeb28ed9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-google-genai==2.0.9 in /home/alex/.local/lib/python3.12/site-packages (2.0.9)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/alex/.local/lib/python3.12/site-packages (from langchain-google-genai==2.0.9) (1.2.0)\n",
      "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /home/alex/.local/lib/python3.12/site-packages (from langchain-google-genai==2.0.9) (0.8.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /home/alex/.local/lib/python3.12/site-packages (from langchain-google-genai==2.0.9) (0.3.49)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /home/alex/.local/lib/python3.12/site-packages (from langchain-google-genai==2.0.9) (2.11.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/alex/.local/lib/python3.12/site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /home/alex/.local/lib/python3.12/site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in /home/alex/.local/lib/python3.12/site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/alex/.local/lib/python3.12/site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /home/alex/.local/lib/python3.12/site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (5.29.3)\n",
      "Requirement already satisfied: tqdm in /home/alex/.local/lib/python3.12/site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/alex/.local/lib/python3.12/site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/alex/.local/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.26.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/alex/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (0.3.19)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/alex/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/alex/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/lib/python3/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/alex/.local/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai==2.0.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /home/alex/.local/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai==2.0.9) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/alex/.local/lib/python3.12/site-packages (from pydantic<3,>=2->langchain-google-genai==2.0.9) (0.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/alex/.local/lib/python3.12/site-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/lib/python3/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/alex/.local/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/alex/.local/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/alex/.local/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/alex/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/alex/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/alex/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/alex/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (0.23.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/lib/python3/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/alex/.local/lib/python3.12/site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/alex/.local/lib/python3.12/site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/alex/.local/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/alex/.local/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/alex/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (4.8.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/alex/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/alex/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/alex/.local/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/alex/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai==2.0.9 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e442e2-4323-445f-a410-2d6519e55ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.chat_sessions import ChatSession\n",
    "import os\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta \n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../libraries')\n",
    "from database import get_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12250ab-b69b-4c06-a29a-60be46677e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde046fa-8427-4938-a3c0-d100005b6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "model = load_model('model_stmp.h5', custom_objects={'mse': losses.MeanSquaredError()})\n",
    "encoders = joblib.load('encoders.pkl')\n",
    "scaler = encoders['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8797421-a832-4825-b1f4-985147c9c5fa",
   "metadata": {},
   "source": [
    "## MAIN CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8212d-8587-47b6-9204-df7c20cfbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template('''\n",
    "{context}\n",
    "\n",
    "Given the user question below, classify it as either being about `Prediction`, `Insights`, or `General`. \n",
    "- If the question follows the context given above, classify it in either of the topics above. \\\n",
    "    Take in mind that for prediction should be in future data and not past data, and for Insights is based on the previous data.\n",
    "- If the question does not match the context or is outside of the context, classify it as `General`.\n",
    "\n",
    "Respond with ONLY one word: the classification.\n",
    "\n",
    "Question: \n",
    "{question}\n",
    "\n",
    "Classification:''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ebb2f-58dc-4477-aef4-9cb73638d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (prompt | llm | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467087b7-6954-421c-8067-d23d6fd65402",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "Act as an inventory manager for Global Trends Apparel (GTA), an international \\\n",
    "fashion retailer operating in 10 countries. Your role is to manage inventory across \\\n",
    "200 stores and warehouses, ensuring stock levels are optimized to avoid \\\n",
    "stockouts and overstocking. You must consider regional demand, seasonality, and cultural factors.\n",
    "\n",
    "Business Context: GTA offers a wide range of products, including casual wear, activewear, and seasonal fashion. \\\n",
    "The company operates in various regions with different climates and shopping patterns. \\\n",
    "Efficient inventory management is crucial for meeting customer demand and minimizing costs.\n",
    "\n",
    "Challenges:\n",
    "\n",
    "    - Stockouts in high-demand regions.\n",
    "    - Overstocking in low-demand regions.\n",
    "    - Difficulty forecasting demand due to changing seasons and local events.\n",
    "    - Inventory movement between stores across regions.\n",
    "    - Delayed replenishment of popular items.\n",
    "\n",
    "Objective:\n",
    "\n",
    "    - Forecast demand based on regional factors.\n",
    "    - Optimize stock levels to prevent stockouts and overstocking.\n",
    "    - Recommend inventory movements between stores.\n",
    "    - Provide alerts for timely replenishment.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d79cf3-2ff7-49ae-a786-d1c8b76d0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = '''\n",
    "CREATE TABLE products (\n",
    "    gtin            CHAR(13),\n",
    "    product_code    VARCHAR(15),\n",
    "    size            VARCHAR(10),\n",
    "    color           VARCHAR(30),\n",
    "    label           VARCHAR(100),\n",
    "    category        VARCHAR(50),\n",
    "\n",
    "    PRIMARY KEY (gtin, product_code)\n",
    ");\n",
    "\n",
    "CREATE TABLE sales (\n",
    "    sku         VARCHAR(15),\n",
    "    quantity    SMALLINT,\n",
    "    site_code   VARCHAR(8),\n",
    "    date        DATE\n",
    ");\n",
    "\n",
    "CREATE TABLE soh (\n",
    "    site_code   VARCHAR(8),\n",
    "    sku         VARCHAR(15),\n",
    "    quantity    INTEGER,\n",
    "    date        DATE, \n",
    "\n",
    "    PRIMARY KEY (site_code, sku, date) -- composed pk\n",
    ");\n",
    "CREATE INDEX idx_sales_sku_site_code ON sales (sku, site_code);\n",
    "CREATE INDEX idx_soh_site_sku_date ON soh (site_code, sku, date);\n",
    "CREATE INDEX idx_products_category ON products (category);\n",
    "\n",
    "CREATE MATERIALIZED VIEW soh_batch_3_months as \n",
    "SELECT \n",
    "    sku,\n",
    "    site_code,\n",
    "    DATE_TRUNC('quarter', date) AS batch_date,\n",
    "    quantity\n",
    "FROM (\n",
    "    SELECT \n",
    "        sku,\n",
    "        site_code,\n",
    "        date,\n",
    "        quantity,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY sku, site_code, DATE_TRUNC('quarter', date)\n",
    "            ORDER BY date DESC\n",
    "        ) AS row_number\n",
    "    FROM soh\n",
    ") subquery\n",
    "WHERE row_number = 1;\n",
    "\n",
    "-- take in mind that the soh table stores only the information of actual stock based on the date, sku and site_code\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f170a-2daa-4c55-b826-fd968daf4993",
   "metadata": {},
   "source": [
    "## BRANCHES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8b3aa-07d2-4992-b9d7-aa52ae3f2b35",
   "metadata": {},
   "source": [
    "### GENERAL QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891a608-d1ef-4ec8-b676-37da1bc7ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_chain = (\n",
    "    PromptTemplate.from_template('''\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "1.  Begin with a polite greeting.\n",
    "2.  Clearly and concisely introduce yourself and your purpose, drawing directly from the provided context.\n",
    "3.  State the specific tasks or questions you are designed to handle.\n",
    "4.  Maintain a professional and helpful tone.\n",
    "5.  Keep the introduction brief and to the point.\n",
    "6.  Do not invent functionalities that are not described in the context.\n",
    "7.  Output ONLY the introduction. Do not include any additional explanations or markdown formatting.\n",
    "    ''')\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa79b9-bfea-4535-bf86-35372f4ad254",
   "metadata": {},
   "source": [
    "### FORECASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9c1b4-8552-4aa5-8c6e-d2ecabafaafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_chain = (\n",
    "    PromptTemplate.from_template('''\n",
    "{context}\n",
    "\n",
    "Please carefully analyze the provided question and extract the following information in the JSON format:\n",
    "\n",
    "- **start_date**: The start date in the format **%Y-%m-%d**. If not specified, then today.\n",
    "- **end_date**: The end date in the format **%Y-%m-%d**. If not specified, then today.\n",
    "- **categories**: A list of categories, which must be one or more of the following values:  \n",
    "  `['Outerwear', 'Tops', 'Bottoms', 'Dresses', 'Swimwear', 'Activewear', 'Footwear', 'Accessories']`. \n",
    "  If no categories are specified, try to extract them from the products mentioned in the question. \\\n",
    "  Return all categories by default if no categories can be identified from the products. \\\n",
    "  Always you need to output the categories from the list above following the format for each category\n",
    "- **countries**: A list of countries where the company has a presence. The list of possible countries is:  \n",
    "  `['USA', 'Canada', 'UK', 'France', 'Germany', 'Australia', 'India', 'Japan', 'Brazil', 'Mexico']`.\n",
    "\n",
    "Please ensure the following rules are followed:\n",
    "\n",
    "1. **Date Format**: Both the **start_date** and **end_date** MUST be in the format: **%Y-%m-%d**.\n",
    "2. **Categories**: If the question doesn't specify categories, attempt to infer them from the products mentioned. \\\n",
    "    If that isn't possible, include all categories by default.\n",
    "3. **Countries**: Only include countries from the list of valid countries where the company is present.\n",
    "\n",
    "Question:  \n",
    "{question}\n",
    "\n",
    "Result:\n",
    "    ''')\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e5ac8-218f-47e8-ab85-29d249da0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predictions_chain = (\n",
    "    PromptTemplate.from_template('''\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Task:\n",
    "Based on predicted sales and current inventory levels, provide a concise and actionable inventory management plan.\n",
    "\n",
    "Predicted Sales:\n",
    "{data}\n",
    "\n",
    "Current Inventory Levels:\n",
    "{inventory}\n",
    "\n",
    "Instructions:\n",
    "1.  Analyze the predicted sales data and current inventory levels to identify potential stockout or overstocking risks.\n",
    "2.  Prioritize inventory adjustments for high-demand products and critical categories.\n",
    "3.  Formulate a strategy to minimize stockouts by recommending restocking or reallocation of products.\n",
    "4.  Develop a plan to avoid overstocking by suggesting inventory reductions or controlled replenishment.\n",
    "5.  Focus on efficient product distribution across stores to meet demand without excessive inventory.\n",
    "6.  Consider store capacity and predicted demand when suggesting inventory adjustments.\n",
    "7.  Provide a clear and brief inventory management plan with specific, actionable business decisions.\n",
    "8.  Do not provide in-depth calculations. Only provide the final business decision.\n",
    "9.  Output ONLY the actionable inventory management plan. Do not include any additional explanations or markdown formatting.\n",
    "\n",
    "Response:\n",
    "    ''')\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4bd26-df3a-4b89-b321-5f3501953bb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_site_codes(): \n",
    "    return get_results('''\n",
    "SELECT \n",
    "    DISTINCT site_code\n",
    "FROM \n",
    "    sales\n",
    "    ''').site_code.values\n",
    "def segregate_site_codes(countries):\n",
    "    site_codes = get_site_codes()\n",
    "    result = []\n",
    "    for site_code in site_codes:\n",
    "        for country in countries:\n",
    "            if site_code.startswith(country.upper()):\n",
    "                result.append(site_code)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa47aba-9cea-4fd5-b760-cd68a2c6aba4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(skus, site_codes):\n",
    "    \"\"\"Loads the data from cloud storage\"\"\"\n",
    "    formatted_skus = ', '.join(f\"'{sku}'\" for sku in skus)\n",
    "\n",
    "    formatted_site_codes = ', '.join(f\"'{site_code}'\" for site_code in site_codes)\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            s.sku, \n",
    "            SUM(s.quantity) as quantity, \n",
    "            s.date, \n",
    "            s.site_code, \n",
    "            p.category\n",
    "        FROM \n",
    "            sales s\n",
    "        LEFT JOIN \n",
    "            products p on p.product_code = s.sku\n",
    "        WHERE \n",
    "            s.sku IN ({formatted_skus}) AND s.site_code IN ({formatted_site_codes})\n",
    "        GROUP BY \n",
    "            s.date, s.sku, p.category, s.site_code\n",
    "        ORDER BY \n",
    "            s.site_code, s.sku, s.date\n",
    "    \"\"\"\n",
    "    return get_results(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c5a49-4081-4f6f-9272-4d577fe7427d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df_batch, encoders):\n",
    "    df_batch['date'] = pd.to_datetime(df_batch['date'])\n",
    "    df_batch['day_of_week'] = df_batch['date'].dt.dayofweek\n",
    "    df_batch['month'] = df_batch['date'].dt.month\n",
    "\n",
    "    df_batch['site_code'] = encoders['site_code'].transform(df_batch['site_code'])\n",
    "    df_batch['sku'] = encoders['sku'].transform(df_batch['sku'])\n",
    "    df_batch['category'] = encoders['category'].transform(df_batch['category'])\n",
    "    df_batch['season'] = df_batch['date'].apply(lambda x: (x.month - 1) // 3)\n",
    "    df_batch['season'] = encoders['season'].transform(df_batch['season'])\n",
    "\n",
    "    numerical_features = ['quantity', 'day_of_week', 'month']\n",
    "    scaler = StandardScaler()\n",
    "    df_batch[numerical_features] = scaler.fit_transform(df_batch[numerical_features])\n",
    "\n",
    "    return df_batch, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14e193-f560-40e6-8cf3-7efbe8aaa5e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_batch(df_batch, sequence_length):\n",
    "    numerical_data = df_batch[['quantity', 'day_of_week', 'month']].values\n",
    "    site_code_data = df_batch['site_code'].values\n",
    "    sku_data = df_batch['sku'].values\n",
    "    category_data = df_batch['category'].values\n",
    "    season_data = df_batch['season'].values\n",
    "    target_data = df_batch['quantity'].values\n",
    "\n",
    "    numerical_batches = []\n",
    "    site_code_batches = []\n",
    "    sku_batches = []\n",
    "    category_batches = []\n",
    "    season_batches = []\n",
    "    target_batches = []\n",
    "\n",
    "    for i in range(0, len(df_batch) - sequence_length):\n",
    "        numerical_batches.append(numerical_data[i:i + sequence_length])\n",
    "        site_code_batches.append(site_code_data[i:i + sequence_length])\n",
    "        sku_batches.append(sku_data[i:i + sequence_length])\n",
    "        category_batches.append(category_data[i:i + sequence_length])\n",
    "        season_batches.append(season_data[i:i + sequence_length])\n",
    "        target_batches.append(target_data[i + sequence_length])\n",
    "\n",
    "    numerical_batches = pad_sequences(numerical_batches, dtype='float32')\n",
    "    site_code_batches = pad_sequences(site_code_batches, dtype='int32')\n",
    "    sku_batches = pad_sequences(sku_batches, dtype='int32')\n",
    "    category_batches = pad_sequences(category_batches, dtype='int32')\n",
    "    season_batches = pad_sequences(season_batches, dtype='int32')\n",
    "    target_batches = np.array(target_batches)\n",
    "\n",
    "    return numerical_batches, site_code_batches, sku_batches, category_batches, season_batches, target_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2307aa6-91ff-4762-a8bd-f8e59ffc0068",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(sku, site_code, sequence_length=10, prediction_dates=None):\n",
    "    \"\"\"Makes predictions using the trained model for specified dates.\"\"\"\n",
    "\n",
    "    skus = [sku]\n",
    "    site_codes = [site_code]\n",
    "    df_predict = load_data(skus, site_codes)\n",
    "\n",
    "    # Filter by dates if provided\n",
    "    if prediction_dates is not None:\n",
    "        #df_predict['date'] = pd.to_datetime(df_predict['date'])\n",
    "\n",
    "        if df_predict.empty: return None\n",
    "\n",
    "    df_predict, _ = preprocess_data(df_predict, encoders)\n",
    "    numerical_batches, site_code_batches, sku_batches, category_batches, season_batches, _ = create_batch(df_predict, sequence_length)\n",
    "\n",
    "    predictions = model.predict([numerical_batches, site_code_batches, sku_batches, category_batches, season_batches], verbose=0)\n",
    "\n",
    "    original_scale_predictions = scaler.inverse_transform(np.concatenate((np.zeros_like(predictions), np.zeros_like(predictions), predictions), axis=1))[:, 2]\n",
    "\n",
    "    return original_scale_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e254dcc-afb1-47af-8570-96ee63a10acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_branch(x):\n",
    "    try: \n",
    "        \n",
    "        data = forecast_chain.invoke(x)\n",
    "        data =  json.loads(re.sub(r'```json\\n|\\n```','',data))\n",
    "\n",
    "        data['site_codes'] = segregate_site_codes(data['countries'])\n",
    "        \n",
    "        formatted_site_codes = ', '.join(f\"'{site_code}'\" for site_code in data['site_codes'])\n",
    "\n",
    "        inventory = get_results(f'''\n",
    "SELECT \n",
    "    s.sku,\n",
    "    p.category, \n",
    "    SUM(s.quantity) as quantity, \n",
    "    s.date \n",
    "FROM\n",
    "    soh s \n",
    "INNER JOIN \n",
    "    products p ON p.product_code = s.sku\n",
    "WHERE s.site_code in ({formatted_site_codes})\n",
    "    AND date in (\n",
    "            SELECT MAX(date) \n",
    "            FROM soh \n",
    "        ) \n",
    "GROUP BY p.category, s.sku, s.date\n",
    "LIMIT 3;\n",
    "        ''')\n",
    "        skus = inventory.sku.unique().tolist()\n",
    "\n",
    "        prediction_dates = pd.to_datetime([data['start_date'], data['end_date']])\n",
    "        prediction_data = []\n",
    "        for sku in skus:\n",
    "            for site_code in data['site_codes']:\n",
    "                predictions = predict(sku, site_code, prediction_dates=prediction_dates)\n",
    "                if predictions is None: predictions = [0]\n",
    "                prediction_data.append({\n",
    "                    'sku': sku, \n",
    "                    'site_code': site_code,\n",
    "                    'predicted_sales': sum(predictions)\n",
    "                })\n",
    "        predicted_df = pd.DataFrame(prediction_data)\n",
    "        return output_predictions_chain.invoke({\n",
    "            'context': x['context'], \n",
    "            'data': predicted_df,\n",
    "            'inventory': inventory,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'An error occurred, please try again later.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498d0bc-9a79-4ef9-bec9-b49273ebcedd",
   "metadata": {},
   "source": [
    "### Insights chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea5fc4-9a5e-4741-b71b-cd6a0031ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_chain = (\n",
    "    PromptTemplate.from_template('''\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Objective:\n",
    "Generate an optimized SQL query to answer the user's question, focusing on delivering data suitable for insightful visualizations.\n",
    "\n",
    "Database Schema:\n",
    "{schemas}\n",
    "\n",
    "User Query:\n",
    "{question}\n",
    "\n",
    "Requirements:\n",
    "1.  Craft a single SQL query that directly addresses the user's information request.\n",
    "2.  Design the query with data visualization in mind. This includes:\n",
    "    * Appropriate aggregations (SUM, AVG, COUNT, etc.).\n",
    "    * Effective grouping (GROUP BY clauses).\n",
    "    * Sorting (ORDER BY clauses) for clear presentation.\n",
    "    * Use of aliases for readability.\n",
    "3.  Ensure the query is efficient and adheres to SQL best practices.\n",
    "4.  If the query involves date/time manipulations, handle these data types correctly.\n",
    "5.  If the user's query suggests comparisons or trend analysis, reflect this in the SQL structure.\n",
    "6.  Return ONLY the SQL query. No additional text, explanations, or markdown formatting is required.\n",
    "7.  Strictly rely on the provided database schema. Do not invent or assume data that is not present.\n",
    "8.  **Site Code Handling:**\n",
    "    * When filtering by `site_code`, be aware that stores are located in the following countries: `['USA', 'Canada', 'UK', 'France', 'Germany', 'Australia', 'India', 'Japan', 'Brazil', 'Mexico']`.\n",
    "    * Site codes follow a pattern: `[Country Code]000` (e.g., `USA001`, `CAN002`).\n",
    "    * The `UK` site codes follow the format `UK000`.\n",
    "9.  **Category Handling:**\n",
    "    * When filtering by `category`, use only the following categories: `['Outerwear', 'Tops', 'Bottoms', 'Dresses', 'Swimwear', 'Activewear', 'Footwear', 'Accessories']`.\n",
    "10. **Product Code Restriction:**\n",
    "    * Do not attempt to generate or query based on product codes or any similar identifiers not explicitly defined in the provided schema.\n",
    "\n",
    "Output:\n",
    "    ''')\n",
    "    | llm \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb113-a640-416b-86f4-666d634af994",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_insights_chain = (\n",
    "    PromptTemplate.from_template('''\n",
    "Task:\n",
    "You are an expert data formatter. Your task is to take the provided Pandas DataFrame and present it in a clear, \\\n",
    "concise, and user-friendly format. The goal is to make the data easily digestible and understandable for a non-technical user. \\\n",
    "Based on the question of the user: \n",
    "\n",
    "Question: \n",
    "{question}\n",
    "\n",
    "Input:\n",
    "{data}\n",
    "\n",
    "Instructions:\n",
    "1.  **Readability:** Prioritize readability. Use clear and descriptive column names. \\\n",
    "If necessary, rephrase column names to be more user-friendly.\n",
    "2.  **Conciseness:** Avoid overwhelming the user with unnecessary details. Focus on the most important information.\n",
    "3.  **Context:** Provide a brief introductory sentence or two explaining the data being presented.\n",
    "4.  **Formatting:** Use appropriate formatting techniques to enhance clarity, such as:\n",
    "    * Rounding numerical values to a reasonable number of decimal places.\n",
    "    * Formatting dates into a user-friendly format (e.g., \"YYYY-MM-DD\").\n",
    "    * Using commas or other separators for large numbers.\n",
    "5.  **Summarization:** If the DataFrame is large, provide a summary of key findings or trends.\n",
    "6.  **Avoid Technical Jargon:** Use plain language that is easily understandable by a non-technical audience.\n",
    "7.  **Table Presentation:** if it is a table, present it as a table using markdown format.\n",
    "8.  **List Presentation:** If it is a list, present it as a clear list.\n",
    "9.  **Do not invent data:** strictly use the data provided.\n",
    "10. **Do not perform any calculations or data analysis:** only format the data.\n",
    "11. **Output ONLY the formatted data and the intro text**. \\\n",
    "Do not include any additional explanations or markdown formatting outside of the table or list.\n",
    "\n",
    "Output:\n",
    "    ''')\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a418233-b66b-4940-bf13-ccccf2ecbbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insights_branch(x):\n",
    "    sql = insights_chain.invoke(x)\n",
    "    sql = re.sub(r'```sql\\n|\\n```','',sql)\n",
    "    data = get_results(sql)\n",
    "    return output_insights_chain.invoke({\n",
    "        'data': data,\n",
    "        'question': x['question']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc75e86-f2e9-499f-97ea-37b97a3ab4db",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf577ca8-eb7e-4891-8d29-e6542213f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = RunnableBranch(\n",
    "    (lambda x: 'prediction' in x['topic'].lower(), prediction_branch),\n",
    "    (lambda x: 'insights' in x['topic'].lower(), insights_branch),\n",
    "    general_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835ecdd-07a8-46de-83a8-745641eaa599",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    {\n",
    "        'topic': chain, \n",
    "        'question': lambda x: x['question'], \n",
    "        'context': lambda x: x['context'],\n",
    "        'schemas': lambda x: x['schemas'],\n",
    "    } \n",
    "    | decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d989d-0368-4d5c-8ec6-52700d2d33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question):\n",
    "    return full_chain.invoke({\n",
    "        'question': question,\n",
    "        'context': context,\n",
    "        'schemas': schemas,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc4f7f-1a45-40a3-bb49-83e400b7e1ad",
   "metadata": {},
   "source": [
    "## PREDICTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131195f-feac-4a7d-84a3-5a73cf450510",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response('Predict the stock qty from stores in America in the next 3 months from tops and earings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0e5c4-736c-418c-bce9-41f25c9d0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response('Hello! I need to know the top 10 slowest stocks from the last record in any store near London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd9673-2128-4cdf-a9bb-dd3aec8721e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response('Hello!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
